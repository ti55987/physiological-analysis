{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from data_utils.data_utils import load_data_from_dir, AUDIO_BLOCKS\n",
    "from features.labels import get_user_rating_raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.psd import get_psd_by_channel\n",
    "from features.constants import EEG_BANDS\n",
    "\n",
    "def get_block_features(\n",
    "    blocks, subject_data, marker, channel, feature,\n",
    "):\n",
    "    features = []\n",
    "    for b in blocks:\n",
    "        block_data = subject_data[b]\n",
    "        psd_data = get_psd_by_channel(block_data, marker, channel, feature)\n",
    "\n",
    "        features = np.vstack((psd_data, features)) if len(features) > 0 else psd_data\n",
    "    return features\n",
    "\n",
    "def get_eeg_channel_feature_to_data(\n",
    "    subject_data, block_list, feature_list,\n",
    "):\n",
    "    channel_feature_to_data = {\"A\": {}, \"B\": {}, \"C\": {}, \"D\": {}}\n",
    "    for c in channel_feature_to_data.keys():\n",
    "        for f in feature_list:\n",
    "            raw_data = get_block_features(block_list, subject_data, \"EEG\", c, f)\n",
    "            channel_feature_to_data[c][f.name] = raw_data\n",
    "\n",
    "    return channel_feature_to_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract EEG spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"  # Replace with your own data dir\n",
    "\n",
    "subject_list = []\n",
    "valence_labels, arousal_labels, label_thresholds = [], [], []\n",
    "marker_features = []\n",
    "for i, d in enumerate(os.listdir(data_dir)):\n",
    "    dir_name = data_dir + d\n",
    "    if not os.path.isdir(dir_name):\n",
    "        continue\n",
    "\n",
    "    subject_data = load_data_from_dir(dir_name)\n",
    "    features = get_eeg_channel_feature_to_data(\n",
    "        subject_data, AUDIO_BLOCKS, EEG_BANDS.keys(),\n",
    "    )\n",
    "    marker_features.append(features)\n",
    "    subject_list.append(d)\n",
    "    # get user rating valence and arousal\n",
    "    vl, arl, _ = get_user_rating_raw_labels(subject_data, AUDIO_BLOCKS)\n",
    "    valence_labels.append(vl)\n",
    "    arousal_labels.append(arl)\n",
    "    label_thresholds.append((np.mean(vl), np.mean(arl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional save your features/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"result/eeg_features.pkl\", \"wb\") as handle:\n",
    "    d = {\"eeg_features\": marker_features}\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"result/behavioral_labels.pkl\", \"wb\") as handle:\n",
    "    d = {\n",
    "        \"valence_labels\": valence_labels,\n",
    "        \"arousal_labels\": arousal_labels,\n",
    "        \"label_thresholds\": label_thresholds,\n",
    "    }\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training with CEBRA + KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils.dataset import get_consecutive_validation_indexes\n",
    "from training_utils.dataset import DatasetBuilder\n",
    "\n",
    "n_trial_per_block = 13\n",
    "n_step_trial = 3\n",
    "val_indexes = [\n",
    "    get_consecutive_validation_indexes(\n",
    "        len(valence_labels[0]), len(AUDIO_BLOCKS), 1, i, n_step_trial\n",
    "    )\n",
    "    for i in range(1, n_trial_per_block, n_step_trial)\n",
    "]\n",
    "print(len(val_indexes), val_indexes)\n",
    "\n",
    "dataset_builder = DatasetBuilder(len(valence_labels[0]), val_indexes_group=val_indexes)\n",
    "len(valence_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.features_utils import prepare_eeg_data\n",
    "    \n",
    "def prepare_dataset(\n",
    "    data,\n",
    "    dataset_builder,\n",
    "    labels,\n",
    "    has_all_spectral: bool = False,\n",
    "    filtered_channel: str = \"\",\n",
    "):  \n",
    "    \n",
    "    data_dict = prepare_eeg_data(data, has_all_spectral, filtered_channel)\n",
    "    dataset_dict = {k: {} for k in data_dict.keys()}\n",
    "    for k, feature_to_data in data_dict.items():\n",
    "        for f, fd in feature_to_data.items():\n",
    "            dataset_dict[k][f] = dataset_builder.train_test_split(fd, labels)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils.training import decode_marker_data, get_metadata\n",
    "\n",
    "subject_accuracy_summary = {\n",
    "    \"subject\": [],\n",
    "    \"channel\": [],\n",
    "    'feature': [],\n",
    "    \"label_type\": [],\n",
    "    \"cv_scores\": [],\n",
    "    \"cv_mean_score\": [],\n",
    "}\n",
    "\n",
    "###CHANGE ME####\n",
    "method = 'CEBRA'\n",
    "filtered_channel = 'C'\n",
    "combined_all_spectral = False\n",
    "cebra_output_dim = 24\n",
    "MAX_ITERATION  = 10\n",
    "###############\n",
    "\n",
    "subject_to_embedding = { s: {'valence': [], 'arousal': []} for s in subject_list}\n",
    "\n",
    "for idx in range(len(subject_list)):\n",
    "    subj = subject_list[idx]\n",
    "    print('decoding subject...', subj)\n",
    "\n",
    "    v_thred, a_thred = label_thresholds[idx]\n",
    "    for lt in [\"valence\", \"arousal\"]:\n",
    "        labels = valence_labels[idx] if lt == \"valence\" else arousal_labels[idx]\n",
    "        thred = v_thred if lt == \"valence\" else a_thred\n",
    "\n",
    "        dataset_dict = prepare_dataset(\n",
    "            marker_features[idx],\n",
    "            dataset_builder,\n",
    "            labels,\n",
    "            combined_all_spectral,\n",
    "            filtered_channel,\n",
    "        )\n",
    "\n",
    "        subject_to_embedding[subj][lt], accuracy = decode_marker_data(\n",
    "            dataset_dict, lt, v_thred, a_thred, method, cebra_output_dim, thred, MAX_ITERATION,\n",
    "        )\n",
    "        \n",
    "        all_channels, all_feature_name, cv_scores = get_metadata(accuracy)\n",
    "\n",
    "        subject_accuracy_summary[\"subject\"].extend(\n",
    "            [subj] * len(all_feature_name)\n",
    "        )  \n",
    "        subject_accuracy_summary[\"channel\"].extend(all_channels)\n",
    "        subject_accuracy_summary[\"feature\"].extend(all_feature_name)      \n",
    "        subject_accuracy_summary[\"cv_mean_score\"].extend([round(np.mean(cv_scores), 2)])\n",
    "        subject_accuracy_summary[\"cv_scores\"].extend(cv_scores)\n",
    "        subject_accuracy_summary[\"label_type\"].extend([lt] * len(all_feature_name))\n",
    "\n",
    "subject_accuracy_summary = pd.DataFrame(subject_accuracy_summary)\n",
    "subject_accuracy_summary[\"subject\"] = subject_accuracy_summary[\"subject\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject_accuracy_summary[subject_accuracy_summary.label_type =='valence']['cv_mean_score'].mean())\n",
    "print(subject_accuracy_summary[subject_accuracy_summary.label_type =='arousal']['cv_mean_score'].mean())\n",
    "\n",
    "subject_accuracy_summary[\"channel\"] = subject_accuracy_summary[\"channel\"].astype(str)\n",
    "subject_accuracy_summary.to_csv(f'results/{method}_eeg.csv')\n",
    "\n",
    "subject_accuracy_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subject_accuracy_summary\n",
    "g = sns.swarmplot(\n",
    "    data=data,\n",
    "    x=\"label_type\",\n",
    "    y=\"cv_mean_score\",\n",
    "    hue=\"channel\",\n",
    "    alpha=0.6,\n",
    "    dodge=True,\n",
    "    legend=False,\n",
    ")\n",
    "g.set_ylim((0.2, 1))\n",
    "g.set_yticklabels(np.round(g.get_yticks(), 2), size = 15)\n",
    "g.set_xticklabels(['valence', 'arousal'], size = 15)\n",
    "\n",
    "df_means = (\n",
    "    data.groupby([\"label_type\", \"channel\"])[\"cv_mean_score\"].agg(\"mean\").reset_index()\n",
    ")\n",
    "\n",
    "pp = sns.pointplot(\n",
    "    x=\"label_type\",\n",
    "    y=\"cv_mean_score\",\n",
    "    data=df_means,\n",
    "    hue=\"channel\",\n",
    "    dodge=0.6,\n",
    "    linestyles=\"\",\n",
    "    scale=2.5,\n",
    "    markers=\"_\",\n",
    "    order=[\"valence\", \"arousal\"],\n",
    ")\n",
    "sns.despine(bottom = True, left = True)\n",
    "g.axhline(0.5, color=\"red\", dashes=(2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap = {'valence': '#94b325', 'arousal': '#595eeb'}\n",
    "label_type = 'arousal'\n",
    "best_embedding_idx = []\n",
    "\n",
    "for i, s in enumerate(subject_list):\n",
    "    (\n",
    "        _,\n",
    "        max_idx,\n",
    "        (embeddings, val_embeddings),\n",
    "        (embedding_labels, val_embedding_labels),\n",
    "    ) = subject_to_embedding[s][label_type][0]\n",
    "    abs_corr = []\n",
    "    for idx in range(embeddings.shape[-1]):\n",
    "        corr = np.corrcoef(embeddings[:, idx], embedding_labels)[0, 1]\n",
    "        abs_corr.append(np.abs(corr))\n",
    "    \n",
    "    max_score_index = np.array(abs_corr).argmax(axis=0)\n",
    "    best_embedding_idx.append(max_score_index)\n",
    "\n",
    "n_row, n_col = (5, 8)\n",
    "f, axarr = plt.subplots(n_row, n_col, figsize=(3 * n_col, 3 * n_row), sharey=True)\n",
    "for idx, ax in enumerate(axarr.flat):\n",
    "    s = subject_list[idx]\n",
    "    l = f'L{best_embedding_idx[idx]}'\n",
    "    (\n",
    "        name,\n",
    "        max_idx,\n",
    "        (embeddings, val_embeddings),\n",
    "        (embedding_labels, val_embedding_labels),\n",
    "    ) = subject_to_embedding[s][label_type][0]\n",
    "\n",
    "    result = pd.DataFrame({l: embeddings[:, best_embedding_idx[idx]], 'labels': embedding_labels})\n",
    "    sns.regplot(data=result, ci=99, x=l, y='labels', color=colorMap[label_type], line_kws=dict(color=\"r\"), ax=ax)    \n",
    "    corr = np.corrcoef(result[l], embedding_labels)[0, 1]\n",
    "    ax.text(\n",
    "        0.1,\n",
    "        0.95,\n",
    "        \"$r$ = {:.3f}\".format(corr),\n",
    "        horizontalalignment=\"left\",\n",
    "        verticalalignment=\"center\",\n",
    "        color='red',\n",
    "        fontweight='heavy',\n",
    "        transform=ax.transAxes,\n",
    "        size=12,\n",
    "    )    \n",
    "    ax.set_title(f'{s}:{name}')\n",
    "    ax.set(ylim=(0, 1))\n",
    "f.tight_layout(pad=1.8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
